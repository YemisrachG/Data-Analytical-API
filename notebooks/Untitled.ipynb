{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f54e8b65-7517-4d14-9d79-6a04401c718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-12 20:21:35.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1m✅ Logger is working and utils/logger.py is found!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: loguru in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: colorama>=0.3.4 in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (from loguru) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (from loguru) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Create the utils folder and logger.py file\n",
    "os.makedirs(\"utils\", exist_ok=True)\n",
    "with open(\"utils/logger.py\", \"w\") as f:\n",
    "    f.write(\"from loguru import logger\\n\")\n",
    "\n",
    "# Add current directory to Python path\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "# Now safely import logger\n",
    "from utils.logger import logger\n",
    "\n",
    "logger.info(\"✅ Logger is working and utils/logger.py is found!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "505a4113-66f6-434b-9969-0e81ea9d760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (25.1.1)\n",
      "Requirement already satisfied: telethon in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (1.40.0)\n",
      "Requirement already satisfied: python-dotenv in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: loguru in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: pyaes in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (from telethon) (1.6.1)\n",
      "Requirement already satisfied: rsa in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (from telethon) (4.9.1)\n",
      "Requirement already satisfied: colorama>=0.3.4 in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (from loguru) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (from loguru) (1.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\wk 7 data engineering challenge\\data-analytical-api\\venv\\lib\\site-packages (from rsa->telethon) (0.6.1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing API_ID from .env file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m api_id_raw = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mAPI_ID\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_id_raw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMissing API_ID from .env file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m API_ID = \u001b[38;5;28mint\u001b[39m(api_id_raw)\n\u001b[32m     23\u001b[39m API_HASH = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mAPI_HASH\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Missing API_ID from .env file"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once in your notebook or terminal)\n",
    "!pip install --upgrade pip\n",
    "!pip install telethon python-dotenv loguru\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from telethon import TelegramClient\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Validate and get environment variables\n",
    "api_id_raw = os.getenv(\"API_ID\")\n",
    "if api_id_raw is None:\n",
    "    raise ValueError(\"Missing API_ID from .env file\")\n",
    "API_ID = int(api_id_raw)\n",
    "\n",
    "API_HASH = os.getenv(\"API_HASH\")\n",
    "if API_HASH is None:\n",
    "    raise ValueError(\"Missing API_HASH from .env file\")\n",
    "\n",
    "SESSION_NAME = os.getenv(\"SESSION_NAME\")\n",
    "if SESSION_NAME is None:\n",
    "    raise ValueError(\"Missing SESSION_NAME from .env file\")\n",
    "\n",
    "# Telegram channels to scrape\n",
    "CHANNELS = [\n",
    "    \"https://t.me/CheMed123\",\n",
    "    \"https://t.me/lobelia4cosmetics\",\n",
    "    \"https://t.me/tikvahpharma\"\n",
    "]\n",
    "\n",
    "# Prepare folders to store raw data and images\n",
    "TODAY = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "BASE_PATH = f\"data/raw/telegram_messages/{TODAY}\"\n",
    "IMAGE_PATH = f\"data/raw/images/{TODAY}\"\n",
    "os.makedirs(BASE_PATH, exist_ok=True)\n",
    "os.makedirs(IMAGE_PATH, exist_ok=True)\n",
    "\n",
    "# Initialize Telegram client\n",
    "client = TelegramClient(SESSION_NAME, API_ID, API_HASH)\n",
    "\n",
    "async def scrape_channel(channel_url):\n",
    "    channel_name = channel_url.split(\"/\")[-1]\n",
    "    logger.info(f\"Scraping channel: {channel_name}\")\n",
    "    messages_data = []\n",
    "    channel_img_path = os.path.join(IMAGE_PATH, channel_name)\n",
    "    os.makedirs(channel_img_path, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        async for message in client.iter_messages(channel_url, limit=100):\n",
    "            msg = {\n",
    "                \"id\": message.id,\n",
    "                \"date\": str(message.date),\n",
    "                \"sender_id\": message.sender_id,\n",
    "                \"text\": message.text,\n",
    "                \"has_photo\": bool(message.photo),\n",
    "                \"channel\": channel_name\n",
    "            }\n",
    "\n",
    "            if message.photo:\n",
    "                image_name = f\"{message.id}.jpg\"\n",
    "                image_path = os.path.join(channel_img_path, image_name)\n",
    "                try:\n",
    "                    await client.download_media(message.photo, file=image_path)\n",
    "                    msg[\"image_path\"] = image_path\n",
    "                    logger.debug(f\"Downloaded image: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Image download failed: {e}\")\n",
    "                    msg[\"image_path\"] = None\n",
    "\n",
    "            messages_data.append(msg)\n",
    "\n",
    "        # Save messages JSON file\n",
    "        out_file = os.path.join(BASE_PATH, f\"{channel_name}.json\")\n",
    "        with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(messages_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        logger.success(f\"Scraped and saved {len(messages_data)} messages from {channel_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error scraping {channel_url}: {e}\")\n",
    "\n",
    "async def main():\n",
    "    await client.start()\n",
    "    tasks = [scrape_channel(url.strip()) for url in CHANNELS if url.strip()]\n",
    "    await asyncio.gather(*tasks)\n",
    "    await client.disconnect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7cf72c-115b-4233-acc9-2cdca822e09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
